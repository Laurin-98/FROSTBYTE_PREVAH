{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "95edec3c1e6c1978"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert CAMELS data to a readable form for Frostbyte",
   "id": "de4131fb489e83e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:04:09.731504Z",
     "start_time": "2024-10-11T12:04:09.725501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np"
   ],
   "id": "b75ac0b455290f8c",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:04:34.357083Z",
     "start_time": "2024-10-11T12:04:09.830360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CAMELES Data\n",
    "CAMELS_data_path = Path('../CH_data/CAMELS')\n",
    "# Automatisch alle CSV-Dateien im Ordner auflisten\n",
    "csv_files = list(CAMELS_data_path.glob('*.csv'))\n",
    "\n",
    "# Leere Listen für Daten, Station IDs und Zeit\n",
    "data_list = []\n",
    "station_ids = []\n",
    "time_list = []\n",
    "\n",
    "# Alle CSV-Dateien durchgehen und Daten sammeln\n",
    "for file_path in csv_files:\n",
    "    # Extrahiere die Station-ID aus dem Dateinamen\n",
    "    station_id = file_path.stem.split('_')[-1]\n",
    "    station_ids.append(station_id)\n",
    "\n",
    "    # Lade die CSV-Datei\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    #print(f'Processing {file_path.name} with columns: {df.columns}')\n",
    "\n",
    "    # Annahme: Die CSV hat eine Spalte 'date', die umgewandelt wird\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "\n",
    "    # Füge Zeitwerte zur Zeitliste hinzu, falls sie nicht leer ist\n",
    "    if not time_list:  # Überprüfen, ob time_list leer ist\n",
    "        time_list = df['date'].tolist()  # Konvertiere zu einer Liste\n",
    "\n",
    "    # Sammle die Daten für diese Station\n",
    "    data_list.append(df[['discharge_vol(m3/s)', 'waterlevel(m)', 'precipitation(mm/d)',\n",
    "                         'temperature_min(°C)', 'temperature_mean(°C)', 'temperature_max(°C)',\n",
    "                         'rel_sun_dur(%)', 'swe(mm)']].values)\n",
    "\n",
    "# Staple die Daten entlang der Stationsachse (axis=1)\n",
    "data_array = np.stack(data_list, axis=1)\n",
    "# Automatisch alle CSV-Dateien im Ordner auflisten\n",
    "csv_files = list(CAMELS_data_path.glob('*.csv'))\n",
    "\n",
    "# Leere Listen für Daten, Station IDs und Zeit\n",
    "data_list = []\n",
    "station_ids = []\n",
    "time_list = []\n",
    "\n",
    "# Alle CSV-Dateien durchgehen und Daten sammeln\n",
    "for file_path in csv_files:\n",
    "    # Extrahiere die Station-ID aus dem Dateinamen\n",
    "    station_id = file_path.stem.split('_')[-1]\n",
    "    station_ids.append(station_id)\n",
    "\n",
    "    # Lade die CSV-Datei\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    #print(f'Processing {file_path.name} with columns: {df.columns}')\n",
    "\n",
    "    # Annahme: Die CSV hat eine Spalte 'date', die umgewandelt wird\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "\n",
    "    # Füge Zeitwerte zur Zeitliste hinzu, falls sie nicht leer ist\n",
    "    if not time_list:  # Überprüfen, ob time_list leer ist\n",
    "        time_list = df['date'].tolist()  # Konvertiere zu einer Liste\n",
    "\n",
    "    # Sammle die Daten für diese Station\n",
    "    data_list.append(df[['discharge_vol(m3/s)', 'waterlevel(m)', 'precipitation(mm/d)',\n",
    "                         'temperature_min(°C)', 'temperature_mean(°C)', 'temperature_max(°C)',\n",
    "                         'rel_sun_dur(%)', 'swe(mm)']].values)\n",
    "\n",
    "# Staple die Daten entlang der Stationsachse (axis=1)\n",
    "data_array = np.stack(data_list, axis=1)\n",
    "\n",
    "# Dataset erstellen\n",
    "Camels_dataset = xr.Dataset(\n",
    "    {\n",
    "        'discharge_vol': (('time', 'Station_ID'), data_array[:, :, 0]),\n",
    "        'waterlevel': (('time', 'Station_ID'), data_array[:, :, 1]),\n",
    "        'precipitation': (('time', 'Station_ID'), data_array[:, :, 2]),\n",
    "        'temperature_min': (('time', 'Station_ID'), data_array[:, :, 3]),\n",
    "        'temperature_mean': (('time', 'Station_ID'), data_array[:, :, 4]),\n",
    "        'temperature_max': (('time', 'Station_ID'), data_array[:, :, 5]),\n",
    "        'rel_sun_dur': (('time', 'Station_ID'), data_array[:, :, 6]),\n",
    "        'swe': (('time', 'Station_ID'), data_array[:, :, 7])\n",
    "    },\n",
    "    coords={\n",
    "        'time': ('time', time_list),  # Zeit ist jetzt korrekt definiert\n",
    "        'Station_ID': ('Station_ID', station_ids)  # Korrektur hier: fügen Sie die Dimension an\n",
    "    }\n",
    ")\n",
    "\n",
    "# Längen- und Breitengrad Koordinaten aus CSV hinzufügen\n",
    "coordinates_df = pd.read_csv('../CH_data/gauge_coordinates.csv', dtype={'gauge_id': str})\n",
    "\n",
    "\n",
    "# Konvertiere station_ids in string\n",
    "station_ids = [str(station_id) for station_id in station_ids]  # Konvertiere in str\n",
    "\n",
    "\n",
    "# Erstelle die Koordinaten als DataArrays, bevor du die Werte hinzufügst\n",
    "lon_array = xr.DataArray(np.nan, coords=[station_ids], dims='Station_ID', name='lon')\n",
    "lat_array = xr.DataArray(np.nan, coords=[station_ids], dims='Station_ID', name='lat')\n",
    "\n",
    "# Füge die Koordinaten zum Dataset hinzu\n",
    "Camels_dataset = Camels_dataset.assign_coords(lon=lon_array, lat=lat_array)\n",
    "\n",
    "# Füge Koordinaten in das Dataset ein\n",
    "for index, row in coordinates_df.iterrows():\n",
    "    gauge_id = str(row['gauge_id'])  # Konvertiere gauge_id in String\n",
    "    if gauge_id in station_ids:  # Überprüfen der IDs\n",
    "        # Fügen Sie Koordinaten zu den vorhandenen Koordinaten hinzu\n",
    "        Camels_dataset['lon'].loc[gauge_id] = row['lon']\n",
    "        Camels_dataset['lat'].loc[gauge_id] = row['lat']\n",
    "    else:\n",
    "        print(f\"Gauge ID {gauge_id} not found in station_ids.\")\n",
    "print('this is Camels_dataset:')\n",
    "print(Camels_dataset)"
   ],
   "id": "3aeb47ff09195af3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is Camels_dataset:\n",
      "<xarray.Dataset>\n",
      "Dimensions:           (Station_ID: 331, time: 14610)\n",
      "Coordinates:\n",
      "  * time              (time) datetime64[ns] 1981-01-01 1981-01-02 ... 2020-12-31\n",
      "  * Station_ID        (Station_ID) <U4 '2004' '2007' '2009' ... '6010' '6011'\n",
      "    lon               (Station_ID) float64 7.117 6.324 6.889 ... 8.579 8.649\n",
      "    lat               (Station_ID) float64 46.93 46.67 46.35 ... 45.94 45.7\n",
      "Data variables:\n",
      "    discharge_vol     (time, Station_ID) float64 nan nan 49.8 ... nan nan nan\n",
      "    waterlevel        (time, Station_ID) float64 429.0 nan 374.4 ... nan nan nan\n",
      "    precipitation     (time, Station_ID) float64 0.89 3.17 1.83 ... 0.15 0.46\n",
      "    temperature_min   (time, Station_ID) float64 -1.63 -6.33 ... nan -10.32\n",
      "    temperature_mean  (time, Station_ID) float64 2.02 -2.42 -6.89 ... nan -6.76\n",
      "    temperature_max   (time, Station_ID) float64 3.68 0.46 -2.84 ... nan -3.65\n",
      "    rel_sun_dur       (time, Station_ID) float64 0.84 0.05 31.12 ... nan 63.69\n",
      "    swe               (time, Station_ID) float64 nan nan nan ... 80.0 102.8\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:04:34.510059Z",
     "start_time": "2024-10-11T12:04:34.420140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Qobs Cameles\n",
    "Qobs_Camels = Camels_dataset.copy()\n",
    "\n",
    "# Behalte nur die Variable 'discharge_vol' und benenne sie in 'Flow' um\n",
    "Qobs_Camels = Qobs_Camels[['discharge_vol']].rename({'discharge_vol': 'Flow'})\n",
    "\n",
    "n_stations = Qobs_Camels.dims['Station_ID']\n",
    "\n",
    "# Erstelle ein Array mit der Länge von 'Station_ID', gefüllt mit dem Wert 'CAMELS'\n",
    "source = np.full(n_stations, 'CAMELS')\n",
    "# source als Koordinate hinzufügen\n",
    "Qobs_Camels = Qobs_Camels.assign_coords(source=('Station_ID', source))\n",
    "\n",
    "# Ausgabe des neuen Datasets\n",
    "print('this is Qobs_Camels:')\n",
    "print(Qobs_Camels)\n",
    "\n",
    "\n",
    "# Extract flow data for station with Station_ID '2319'\n",
    "try:\n",
    "    flow_2319 = Qobs_Camels.sel(Station_ID='2319')['Flow']  # Verwende '2319' als String\n",
    "    flow_2319_array = flow_2319.values\n",
    "    print(flow_2319_array)\n",
    "except KeyError:\n",
    "    print(\"Station_ID '2319' not found in Qobs_Camels.\")\n",
    "\n",
    "##\n",
    "Qobs_Camels.to_netcdf('../CH_data/CH_input_data/Qobs_Camels.nc')\n"
   ],
   "id": "ad4030c250cbe348",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is Qobs_Camels:\n",
      "<xarray.Dataset>\n",
      "Dimensions:     (Station_ID: 331, time: 14610)\n",
      "Coordinates:\n",
      "  * Station_ID  (Station_ID) <U4 '2004' '2007' '2009' ... '6009' '6010' '6011'\n",
      "    lon         (Station_ID) float64 7.117 6.324 6.889 ... 8.525 8.579 8.649\n",
      "    lat         (Station_ID) float64 46.93 46.67 46.35 ... 45.96 45.94 45.7\n",
      "  * time        (time) datetime64[ns] 1981-01-01 1981-01-02 ... 2020-12-31\n",
      "    source      (Station_ID) <U6 'CAMELS' 'CAMELS' ... 'CAMELS' 'CAMELS'\n",
      "Data variables:\n",
      "    Flow        (time, Station_ID) float64 nan nan 49.8 26.26 ... nan nan nan\n",
      "[0.196 0.195 0.195 ... 0.243 0.24  0.238]\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:04:34.935466Z",
     "start_time": "2024-10-11T12:04:34.588694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SWE Camels\n",
    "SWE_Camels = Camels_dataset.copy()\n",
    "#P_Camels = Camels_dataset.copy()\n",
    "\n",
    "SWE_Camels = SWE_Camels[['swe']].rename({'swe': 'snw'})\n",
    "#P_Camels = P_Camels[['precipitation']].rename({'precipitation': 'p'})\n",
    "\n",
    "SWE_Camels = SWE_Camels.drop_vars(['lat', 'lon'])\n",
    "#P_Camels = P_Camels.drop_vars(['lat', 'lon'])\n",
    "\n",
    "# Längen- und Breitengrad Koordinaten aus CSV hinzufügen\n",
    "coordinates_df = pd.read_csv('../CH_data/centroids_coordinates.csv', dtype={'gauge_id': str})\n",
    "\n",
    "# Konvertiere station_ids in string\n",
    "station_ids = [str(station_id) for station_id in station_ids]  # Konvertiere in str\n",
    "\n",
    "# test delete me later\n",
    "# Erstelle die Koordinaten als DataArrays, bevor du die Werte hinzufügst\n",
    "lon_array = xr.DataArray(np.nan, coords=[station_ids], dims='Station_ID', name='lon')\n",
    "lat_array = xr.DataArray(np.nan, coords=[station_ids], dims='Station_ID', name='lat')\n",
    "\n",
    "# Füge die Koordinaten zum Dataset hinzu\n",
    "SWE_Camels = SWE_Camels.assign_coords(lon=lon_array, lat=lat_array)\n",
    "#P_Camels = P_Camels.assign_coords(lon=lon_array, lat=lat_array)\n",
    "\n",
    "# Füge Koordinaten in das Dataset ein\n",
    "for index, row in coordinates_df.iterrows():\n",
    "    gauge_id = str(row['gauge_id'])  # Konvertiere gauge_id in String\n",
    "    if gauge_id in station_ids:  # Überprüfen der IDs\n",
    "        # Fügen Sie Koordinaten zu den vorhandenen Koordinaten hinzu\n",
    "        SWE_Camels['lon'].loc[gauge_id] = row['lon']\n",
    "        SWE_Camels['lat'].loc[gauge_id] = row['lat']\n",
    "        #P_Camels['lon'].loc[gauge_id] = row['lon']\n",
    "        #P_Camels['lat'].loc[gauge_id] = row['lat']\n",
    "    else:\n",
    "        print(f\"Gauge ID {gauge_id} not found in station_ids. (SWE)\")\n",
    "\n",
    "\n",
    "# Füge die station_name Koordinate hinzu\n",
    "station_names = [f\"{station_id}_centroid\" for station_id in SWE_Camels.coords['Station_ID'].values]\n",
    "#station_names = [f\"{station_id}_centroid\" for station_id in P_Camels.coords['Station_ID'].values]\n",
    "\n",
    "# Erstelle die station_name Koordinate als DataArray\n",
    "station_name_array = xr.DataArray(station_names, coords=[SWE_Camels.coords['Station_ID']], dims='Station_ID', name='station_name')\n",
    "#station_name_array = xr.DataArray(station_names, coords=[P_Camels.coords['Station_ID']], dims='Station_ID', name='station_name')\n",
    "\n",
    "# Füge die station_name Koordinate zum Dataset hinzu\n",
    "SWE_Camels = SWE_Camels.assign_coords(station_name=station_name_array)\n",
    "#P_Camels = P_Camels.assign_coords(station_name=station_name_array)\n",
    "\n",
    "# Ausgabe des neuen Datasets mit der station_name Koordinate\n",
    "\n",
    "#print(P_Camels)\n",
    "SWE_Camels = SWE_Camels.rename({'Station_ID': 'station_id'})\n",
    "print('this is SWE_Camels')\n",
    "print(SWE_Camels)\n",
    "SWE_Camels.to_netcdf('../CH_data/CH_input_data/SWE_Camels.nc')\n",
    "#P_Camels.to_netcdf('CH_data/CH_input_data/P_Camels.nc')\n"
   ],
   "id": "7fe81938ab72af0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is SWE_Camels\n",
      "<xarray.Dataset>\n",
      "Dimensions:       (station_id: 331, time: 14610)\n",
      "Coordinates:\n",
      "  * station_id    (station_id) <U4 '2004' '2007' '2009' ... '6009' '6010' '6011'\n",
      "  * time          (time) datetime64[ns] 1981-01-01 1981-01-02 ... 2020-12-31\n",
      "    lon           (station_id) float64 6.899 6.198 7.573 ... 8.455 8.573 8.648\n",
      "    lat           (station_id) float64 46.73 46.58 46.21 ... 46.03 46.0 46.17\n",
      "    station_name  (station_id) <U13 '2004_centroid' ... '6011_centroid'\n",
      "Data variables:\n",
      "    snw           (time, station_id) float64 nan nan nan ... 114.0 80.0 102.8\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:04:35.036988Z",
     "start_time": "2024-10-11T12:04:35.001094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# meteodata / P data\n",
    "P_Camels = Camels_dataset.copy()\n",
    "print(P_Camels)\n",
    "#P_Camels.to_netcdf('../CH_data/CH_input_data/P_Camels.nc')"
   ],
   "id": "ac9231591234cce2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:           (Station_ID: 331, time: 14610)\n",
      "Coordinates:\n",
      "  * time              (time) datetime64[ns] 1981-01-01 1981-01-02 ... 2020-12-31\n",
      "  * Station_ID        (Station_ID) <U4 '2004' '2007' '2009' ... '6010' '6011'\n",
      "    lon               (Station_ID) float64 7.117 6.324 6.889 ... 8.579 8.649\n",
      "    lat               (Station_ID) float64 46.93 46.67 46.35 ... 45.94 45.7\n",
      "Data variables:\n",
      "    discharge_vol     (time, Station_ID) float64 nan nan 49.8 ... nan nan nan\n",
      "    waterlevel        (time, Station_ID) float64 429.0 nan 374.4 ... nan nan nan\n",
      "    precipitation     (time, Station_ID) float64 0.89 3.17 1.83 ... 0.15 0.46\n",
      "    temperature_min   (time, Station_ID) float64 -1.63 -6.33 ... nan -10.32\n",
      "    temperature_mean  (time, Station_ID) float64 2.02 -2.42 -6.89 ... nan -6.76\n",
      "    temperature_max   (time, Station_ID) float64 3.68 0.46 -2.84 ... nan -3.65\n",
      "    rel_sun_dur       (time, Station_ID) float64 0.84 0.05 31.12 ... nan 63.69\n",
      "    swe               (time, Station_ID) float64 nan nan nan ... 80.0 102.8\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:04:35.131541Z",
     "start_time": "2024-10-11T12:04:35.115729Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d2c4ae3ef6a7d896",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
